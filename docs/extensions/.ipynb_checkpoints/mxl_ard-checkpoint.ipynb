{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed logit with ARD\n",
    "\n",
    "We begin by performing the necessary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/rodr/code/amortized-mxl-dev/release\") \n",
    "\n",
    "import logging\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate simulated data\n",
    "\n",
    "We predefine the fixed effects parameters (true_alpha) and random effects parameters (true_beta), as well as the covariance matrix (true_Omega), and sample simulated choice data for 500 respondents (num_resp), each with 5 choice situations (num_menus). The number of choice alternatives is set to 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating fake data...\n",
      "Error: 42.18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALT1_XF1</th>\n",
       "      <th>ALT1_XF2</th>\n",
       "      <th>ALT1_XF3</th>\n",
       "      <th>ALT1_XR1</th>\n",
       "      <th>ALT1_XR2</th>\n",
       "      <th>ALT1_XR3</th>\n",
       "      <th>ALT1_XR4</th>\n",
       "      <th>ALT1_XR5</th>\n",
       "      <th>ALT2_XF1</th>\n",
       "      <th>ALT2_XF2</th>\n",
       "      <th>...</th>\n",
       "      <th>ALT5_XR1</th>\n",
       "      <th>ALT5_XR2</th>\n",
       "      <th>ALT5_XR3</th>\n",
       "      <th>ALT5_XR4</th>\n",
       "      <th>ALT5_XR5</th>\n",
       "      <th>choice</th>\n",
       "      <th>indID</th>\n",
       "      <th>menuID</th>\n",
       "      <th>obsID</th>\n",
       "      <th>ones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374540</td>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.069212</td>\n",
       "      <td>0.585697</td>\n",
       "      <td>0.798869</td>\n",
       "      <td>0.764473</td>\n",
       "      <td>0.837396</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>0.156019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119691</td>\n",
       "      <td>0.938057</td>\n",
       "      <td>0.510089</td>\n",
       "      <td>0.300522</td>\n",
       "      <td>0.624496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.183405</td>\n",
       "      <td>0.304242</td>\n",
       "      <td>0.524756</td>\n",
       "      <td>0.257912</td>\n",
       "      <td>0.040451</td>\n",
       "      <td>0.793656</td>\n",
       "      <td>0.995865</td>\n",
       "      <td>0.956444</td>\n",
       "      <td>0.431945</td>\n",
       "      <td>0.291229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107102</td>\n",
       "      <td>0.495835</td>\n",
       "      <td>0.287860</td>\n",
       "      <td>0.651430</td>\n",
       "      <td>0.145982</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.607545</td>\n",
       "      <td>0.170524</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>0.588614</td>\n",
       "      <td>0.571589</td>\n",
       "      <td>0.402953</td>\n",
       "      <td>0.482491</td>\n",
       "      <td>0.146977</td>\n",
       "      <td>0.948886</td>\n",
       "      <td>0.965632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685591</td>\n",
       "      <td>0.543384</td>\n",
       "      <td>0.531436</td>\n",
       "      <td>0.551352</td>\n",
       "      <td>0.486627</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.662522</td>\n",
       "      <td>0.311711</td>\n",
       "      <td>0.520068</td>\n",
       "      <td>0.946478</td>\n",
       "      <td>0.618740</td>\n",
       "      <td>0.459393</td>\n",
       "      <td>0.860055</td>\n",
       "      <td>0.889657</td>\n",
       "      <td>0.546710</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071816</td>\n",
       "      <td>0.562382</td>\n",
       "      <td>0.314172</td>\n",
       "      <td>0.099657</td>\n",
       "      <td>0.190283</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.388677</td>\n",
       "      <td>0.271349</td>\n",
       "      <td>0.828738</td>\n",
       "      <td>0.790511</td>\n",
       "      <td>0.806431</td>\n",
       "      <td>0.767619</td>\n",
       "      <td>0.075828</td>\n",
       "      <td>0.110584</td>\n",
       "      <td>0.356753</td>\n",
       "      <td>0.280935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174194</td>\n",
       "      <td>0.348183</td>\n",
       "      <td>0.348195</td>\n",
       "      <td>0.824453</td>\n",
       "      <td>0.496267</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ALT1_XF1  ALT1_XF2  ALT1_XF3  ALT1_XR1  ALT1_XR2  ALT1_XR3  ALT1_XR4  \\\n",
       "0  0.374540  0.950714  0.731994  0.069212  0.585697  0.798869  0.764473   \n",
       "1  0.183405  0.304242  0.524756  0.257912  0.040451  0.793656  0.995865   \n",
       "2  0.607545  0.170524  0.065052  0.588614  0.571589  0.402953  0.482491   \n",
       "3  0.662522  0.311711  0.520068  0.946478  0.618740  0.459393  0.860055   \n",
       "4  0.388677  0.271349  0.828738  0.790511  0.806431  0.767619  0.075828   \n",
       "\n",
       "   ALT1_XR5  ALT2_XF1  ALT2_XF2  ...  ALT5_XR1  ALT5_XR2  ALT5_XR3  ALT5_XR4  \\\n",
       "0  0.837396  0.598658  0.156019  ...  0.119691  0.938057  0.510089  0.300522   \n",
       "1  0.956444  0.431945  0.291229  ...  0.107102  0.495835  0.287860  0.651430   \n",
       "2  0.146977  0.948886  0.965632  ...  0.685591  0.543384  0.531436  0.551352   \n",
       "3  0.889657  0.546710  0.184854  ...  0.071816  0.562382  0.314172  0.099657   \n",
       "4  0.110584  0.356753  0.280935  ...  0.174194  0.348183  0.348195  0.824453   \n",
       "\n",
       "   ALT5_XR5  choice  indID  menuID  obsID  ones  \n",
       "0  0.624496       0      0       0      0     1  \n",
       "1  0.145982       2      0       1      1     1  \n",
       "2  0.486627       2      0       2      2     1  \n",
       "3  0.190283       3      0       3      3     1  \n",
       "4  0.496267       3      0       4      4     1  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from core.dcm_fakedata import generate_fake_data_wide\n",
    "\n",
    "num_resp = 2000\n",
    "num_menus = 5\n",
    "num_alternatives = 5\n",
    "\n",
    "# one of the parameters is set to zero such that the corresponding input variables  \n",
    "# is not correlated with the observed choices\n",
    "true_alpha = np.array([-0.8, 0.8, 0]) \n",
    "true_beta = np.array([-0.8, 0.8, 1.0, -0.8, 0])\n",
    "# dynamic version of generating Omega\n",
    "corr = 0.8\n",
    "scale_factor = 1.0\n",
    "true_Omega = corr*np.ones((len(true_beta),len(true_beta))) # off-diagonal values of cov matrix\n",
    "true_Omega[np.arange(len(true_beta)), np.arange(len(true_beta))] = 1.0 # diagonal values of cov matrix\n",
    "true_Omega *= scale_factor\n",
    "\n",
    "df = generate_fake_data_wide(num_resp, num_menus, num_alternatives, true_alpha, true_beta, true_Omega)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Logit specification\n",
    "\n",
    "We now make use of the developed formula interface to specify the utilities of the mixed logit model. \n",
    "\n",
    "We begin by defining the fixed effects parameters, the random effects parameters, and the observed variables. This creates instances of Python objects that can be put together to define the utility functions for the different alternatives.\n",
    "\n",
    "Once the utilities are defined, we collect them in a Python dictionary mapping alternative names to their corresponding expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.dcm_interface import FixedEffect, RandomEffect, ObservedVariable\n",
    "import torch.distributions as dists\n",
    "\n",
    "# define fixed effects parameters\n",
    "B_XF1 = FixedEffect('BETA_XF1')\n",
    "B_XF2 = FixedEffect('BETA_XF2')\n",
    "B_XF3 = FixedEffect('BETA_XF3')\n",
    "\n",
    "# define random effects parameters\n",
    "B_XR1 = RandomEffect('BETA_XR1')\n",
    "B_XR2 = RandomEffect('BETA_XR2')\n",
    "B_XR3 = RandomEffect('BETA_XR3')\n",
    "B_XR4 = RandomEffect('BETA_XR4')\n",
    "B_XR5 = RandomEffect('BETA_XR5')\n",
    "\n",
    "# define observed variables\n",
    "for attr in df.columns:\n",
    "    exec(\"%s = ObservedVariable('%s')\" % (attr,attr))\n",
    "\n",
    "# define utility functions\n",
    "V1 = B_XF1*ALT1_XF1 + B_XF2*ALT1_XF2 + B_XF3*ALT1_XF3 + B_XR1*ALT1_XR1 + B_XR2*ALT1_XR2 + B_XR3*ALT1_XR3 + B_XR4*ALT1_XR4 + B_XR5*ALT1_XR5\n",
    "V2 = B_XF1*ALT2_XF1 + B_XF2*ALT2_XF2 + B_XF3*ALT2_XF3 + B_XR1*ALT2_XR1 + B_XR2*ALT2_XR2 + B_XR3*ALT2_XR3 + B_XR4*ALT2_XR4 + B_XR5*ALT2_XR5\n",
    "V3 = B_XF1*ALT3_XF1 + B_XF2*ALT3_XF2 + B_XF3*ALT3_XF3 + B_XR1*ALT3_XR1 + B_XR2*ALT3_XR2 + B_XR3*ALT3_XR3 + B_XR4*ALT3_XR4 + B_XR5*ALT3_XR5\n",
    "V4 = B_XF1*ALT4_XF1 + B_XF2*ALT4_XF2 + B_XF3*ALT4_XF3 + B_XR1*ALT4_XR1 + B_XR2*ALT4_XR2 + B_XR3*ALT4_XR3 + B_XR4*ALT4_XR4 + B_XR5*ALT4_XR5\n",
    "V5 = B_XF1*ALT5_XF1 + B_XF2*ALT5_XF2 + B_XF3*ALT5_XF3 + B_XR1*ALT5_XR1 + B_XR2*ALT5_XR2 + B_XR3*ALT5_XR3 + B_XR4*ALT5_XR4 + B_XR5*ALT5_XR5\n",
    "\n",
    "# associate utility functions with the names of the alternatives\n",
    "utilities = {\"ALT1\": V1, \"ALT2\": V2, \"ALT3\": V3, \"ALT4\": V4, \"ALT5\": V5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to create a Specification object containing the utilities that we have just defined. Note that we must also specify the type of choice model to be used - a mixed logit model (MXL) in this case.\n",
    "\n",
    "Note that we can inspect the specification by printing the dcm_spec object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- MXL specification:\n",
      "Alternatives: ['ALT1', 'ALT2', 'ALT3', 'ALT4', 'ALT5']\n",
      "Utility functions:\n",
      "   V_ALT1 = BETA_XF1*ALT1_XF1 + BETA_XF2*ALT1_XF2 + BETA_XF3*ALT1_XF3 + BETA_XR1_n*ALT1_XR1 + BETA_XR2_n*ALT1_XR2 + BETA_XR3_n*ALT1_XR3 + BETA_XR4_n*ALT1_XR4 + BETA_XR5_n*ALT1_XR5\n",
      "   V_ALT2 = BETA_XF1*ALT2_XF1 + BETA_XF2*ALT2_XF2 + BETA_XF3*ALT2_XF3 + BETA_XR1_n*ALT2_XR1 + BETA_XR2_n*ALT2_XR2 + BETA_XR3_n*ALT2_XR3 + BETA_XR4_n*ALT2_XR4 + BETA_XR5_n*ALT2_XR5\n",
      "   V_ALT3 = BETA_XF1*ALT3_XF1 + BETA_XF2*ALT3_XF2 + BETA_XF3*ALT3_XF3 + BETA_XR1_n*ALT3_XR1 + BETA_XR2_n*ALT3_XR2 + BETA_XR3_n*ALT3_XR3 + BETA_XR4_n*ALT3_XR4 + BETA_XR5_n*ALT3_XR5\n",
      "   V_ALT4 = BETA_XF1*ALT4_XF1 + BETA_XF2*ALT4_XF2 + BETA_XF3*ALT4_XF3 + BETA_XR1_n*ALT4_XR1 + BETA_XR2_n*ALT4_XR2 + BETA_XR3_n*ALT4_XR3 + BETA_XR4_n*ALT4_XR4 + BETA_XR5_n*ALT4_XR5\n",
      "   V_ALT5 = BETA_XF1*ALT5_XF1 + BETA_XF2*ALT5_XF2 + BETA_XF3*ALT5_XF3 + BETA_XR1_n*ALT5_XR1 + BETA_XR2_n*ALT5_XR2 + BETA_XR3_n*ALT5_XR3 + BETA_XR4_n*ALT5_XR4 + BETA_XR5_n*ALT5_XR5\n",
      "\n",
      "Num. parameters to be estimated: 8\n",
      "Fixed effects params: ['BETA_XF1', 'BETA_XF2', 'BETA_XF3']\n",
      "Random effects params: ['BETA_XR1', 'BETA_XR2', 'BETA_XR3', 'BETA_XR4', 'BETA_XR5']\n"
     ]
    }
   ],
   "source": [
    "from core.dcm_interface import Specification\n",
    "\n",
    "#Logit(choice, utilities, availability, df)\n",
    "#Logit(choice_test, utilities, availability_test, df_test)\n",
    "\n",
    "# create MXL specification object based on the utilities previously defined\n",
    "dcm_spec = Specification('MXL', utilities)\n",
    "print(dcm_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the Specification is defined, we need to define the DCM Dataset object that goes along with it. For this, we instantiate the Dataset class with the Pandas dataframe containing the data in the so-called \"wide format\", the name of column in the dataframe containing the observed choices and the dcm_spec that we have previously created.\n",
    "\n",
    "Note that since this is panel data, we must also specify the name of the column in the dataframe that contains the ID of the respondent (this should be a integer ranging from 0 the num_resp-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n",
      "\tModel type: MXL\n",
      "\tNum. observations: 10000\n",
      "\tNum. alternatives: 5\n",
      "\tNum. respondents: 2000\n",
      "\tNum. menus: 5\n",
      "\tObservations IDs: [   0    1    2 ... 9997 9998 9999]\n",
      "\tAlternative IDs: None\n",
      "\tRespondent IDs: [   0    0    0 ... 1999 1999 1999]\n",
      "\tAvailability columns: None\n",
      "\tAttribute names: ['ALT1_XF1', 'ALT1_XF2', 'ALT1_XF3', 'ALT1_XR1', 'ALT1_XR2', 'ALT1_XR3', 'ALT1_XR4', 'ALT1_XR5', 'ALT2_XF1', 'ALT2_XF2', 'ALT2_XF3', 'ALT2_XR1', 'ALT2_XR2', 'ALT2_XR3', 'ALT2_XR4', 'ALT2_XR5', 'ALT3_XF1', 'ALT3_XF2', 'ALT3_XF3', 'ALT3_XR1', 'ALT3_XR2', 'ALT3_XR3', 'ALT3_XR4', 'ALT3_XR5', 'ALT4_XF1', 'ALT4_XF2', 'ALT4_XF3', 'ALT4_XR1', 'ALT4_XR2', 'ALT4_XR3', 'ALT4_XR4', 'ALT4_XR5', 'ALT5_XF1', 'ALT5_XF2', 'ALT5_XF3', 'ALT5_XR1', 'ALT5_XR2', 'ALT5_XR3', 'ALT5_XR4', 'ALT5_XR5']\n",
      "\tFixed effects attribute names: ['ALT1_XF1', 'ALT1_XF2', 'ALT1_XF3', 'ALT2_XF1', 'ALT2_XF2', 'ALT2_XF3', 'ALT3_XF1', 'ALT3_XF2', 'ALT3_XF3', 'ALT4_XF1', 'ALT4_XF2', 'ALT4_XF3', 'ALT5_XF1', 'ALT5_XF2', 'ALT5_XF3']\n",
      "\tFixed effects parameter names: ['BETA_XF1', 'BETA_XF2', 'BETA_XF3', 'BETA_XF1', 'BETA_XF2', 'BETA_XF3', 'BETA_XF1', 'BETA_XF2', 'BETA_XF3', 'BETA_XF1', 'BETA_XF2', 'BETA_XF3', 'BETA_XF1', 'BETA_XF2', 'BETA_XF3']\n",
      "\tRandom effects attribute names: ['ALT1_XR1', 'ALT1_XR2', 'ALT1_XR3', 'ALT1_XR4', 'ALT1_XR5', 'ALT2_XR1', 'ALT2_XR2', 'ALT2_XR3', 'ALT2_XR4', 'ALT2_XR5', 'ALT3_XR1', 'ALT3_XR2', 'ALT3_XR3', 'ALT3_XR4', 'ALT3_XR5', 'ALT4_XR1', 'ALT4_XR2', 'ALT4_XR3', 'ALT4_XR4', 'ALT4_XR5', 'ALT5_XR1', 'ALT5_XR2', 'ALT5_XR3', 'ALT5_XR4', 'ALT5_XR5']\n",
      "\tRandom effects parameter names: ['BETA_XR1', 'BETA_XR2', 'BETA_XR3', 'BETA_XR4', 'BETA_XR5', 'BETA_XR1', 'BETA_XR2', 'BETA_XR3', 'BETA_XR4', 'BETA_XR5', 'BETA_XR1', 'BETA_XR2', 'BETA_XR3', 'BETA_XR4', 'BETA_XR5', 'BETA_XR1', 'BETA_XR2', 'BETA_XR3', 'BETA_XR4', 'BETA_XR5', 'BETA_XR1', 'BETA_XR2', 'BETA_XR3', 'BETA_XR4', 'BETA_XR5']\n",
      "\tAlternative attributes ndarray.shape: (2000, 5, 40)\n",
      "\tChoices ndarray.shape: (2000, 5)\n",
      "\tAlternatives availability ndarray.shape: (2000, 5, 5)\n",
      "\tData mask ndarray.shape: (2000, 5)\n",
      "\tContext data ndarray.shape: (2000, 0)\n",
      "\tNeural nets data ndarray.shape: (2000, 0)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from core.dcm_interface import Dataset\n",
    "\n",
    "# create DCM dataset object\n",
    "dcm_dataset = Dataset(df, 'choice', dcm_spec, resp_id_col='indID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the specification, we can inspect the DCM dataset by printing the dcm_dataset object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- DCM dataset:\n",
      "Model type: MXL\n",
      "Num. observations: 10000\n",
      "Num. alternatives: 5\n",
      "Num. respondents: 2000\n",
      "Num. menus: 5\n",
      "Num. fixed effects: 15\n",
      "Num. random effects: 25\n",
      "Attribute names: ['ALT1_XF1', 'ALT1_XF2', 'ALT1_XF3', 'ALT1_XR1', 'ALT1_XR2', 'ALT1_XR3', 'ALT1_XR4', 'ALT1_XR5', 'ALT2_XF1', 'ALT2_XF2', 'ALT2_XF3', 'ALT2_XR1', 'ALT2_XR2', 'ALT2_XR3', 'ALT2_XR4', 'ALT2_XR5', 'ALT3_XF1', 'ALT3_XF2', 'ALT3_XF3', 'ALT3_XR1', 'ALT3_XR2', 'ALT3_XR3', 'ALT3_XR4', 'ALT3_XR5', 'ALT4_XF1', 'ALT4_XF2', 'ALT4_XF3', 'ALT4_XR1', 'ALT4_XR2', 'ALT4_XR3', 'ALT4_XR4', 'ALT4_XR5', 'ALT5_XF1', 'ALT5_XF2', 'ALT5_XF3', 'ALT5_XR1', 'ALT5_XR2', 'ALT5_XR3', 'ALT5_XR4', 'ALT5_XR5']\n"
     ]
    }
   ],
   "source": [
    "print(dcm_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Mixed Logit Model in PyTorch\n",
    "\n",
    "It is now time to perform approximate Bayesian inference on the mixed logit model that we have specified. The generative process of the MXL model that we will be using is the following:\n",
    "\n",
    "1. Draw fixed taste parameters $\\boldsymbol\\alpha \\sim \\mathcal{N}(\\boldsymbol\\lambda_0, \\boldsymbol\\Xi_0)$\n",
    "2. Draw mean vector $\\boldsymbol\\zeta \\sim \\mathcal{N}(\\boldsymbol\\mu_0, \\boldsymbol\\Sigma_0)$\n",
    "3. Draw scales vector $\\boldsymbol\\theta \\sim \\mbox{half-Cauchy}(\\boldsymbol\\sigma_0)$\n",
    "4. Draw correlation matrix $\\boldsymbol\\Psi \\sim \\mbox{LKJ}(\\nu)$\n",
    "5. For each decision-maker $n \\in \\{1,\\dots,N\\}$\n",
    "    1. Draw random taste parameters $\\boldsymbol\\beta_n \\sim \\mathcal{N}(\\boldsymbol\\zeta,\\boldsymbol\\Omega)$\n",
    "    2. For each choice occasion $t \\in \\{1,\\dots,T_n\\}$\n",
    "        1. Draw observed choice $y_{nt} \\sim \\mbox{MNL}(\\boldsymbol\\alpha, \\boldsymbol\\beta_n, \\textbf{X}_{nt})$\n",
    "        \n",
    "where $\\boldsymbol\\Omega = \\mbox{diag}(\\boldsymbol\\theta) \\times \\boldsymbol\\Psi \\times  \\mbox{diag}(\\boldsymbol\\theta)$.\n",
    "\n",
    "We can instantiate this model from the TorchMXL using the following code. We can the run variational inference to approximate the posterior distribution of the latent variables in the model. Note that since in this case we know the true parameters that were used to generate the simualated choice data, we can pass them to the \"infer\" method in order to obtain additional information during the ELBO maximization (useful for tracking the progress of VI and for other debugging purposes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch     0] ELBO: 27331; Loglik: -19070; Acc.: 0.215; Alpha RMSE: 0.645; Beta RMSE: 0.764\n",
      "[Epoch   100] ELBO: 20416; Loglik: -16692; Acc.: 0.268; Alpha RMSE: 0.243; Beta RMSE: 0.782\n",
      "[Epoch   200] ELBO: 19115; Loglik: -15509; Acc.: 0.332; Alpha RMSE: 0.072; Beta RMSE: 0.755\n",
      "[Epoch   300] ELBO: 19412; Loglik: -14947; Acc.: 0.364; Alpha RMSE: 0.054; Beta RMSE: 0.706\n",
      "[Epoch   400] ELBO: 18189; Loglik: -14250; Acc.: 0.392; Alpha RMSE: 0.072; Beta RMSE: 0.662\n",
      "[Epoch   500] ELBO: 17680; Loglik: -13711; Acc.: 0.431; Alpha RMSE: 0.061; Beta RMSE: 0.617\n",
      "[Epoch   600] ELBO: 16509; Loglik: -13579; Acc.: 0.438; Alpha RMSE: 0.094; Beta RMSE: 0.556\n",
      "[Epoch   700] ELBO: 16532; Loglik: -13372; Acc.: 0.445; Alpha RMSE: 0.108; Beta RMSE: 0.494\n",
      "[Epoch   800] ELBO: 16481; Loglik: -13274; Acc.: 0.448; Alpha RMSE: 0.103; Beta RMSE: 0.449\n",
      "[Epoch   900] ELBO: 16491; Loglik: -13139; Acc.: 0.461; Alpha RMSE: 0.082; Beta RMSE: 0.381\n",
      "[Epoch  1000] ELBO: 16181; Loglik: -12934; Acc.: 0.465; Alpha RMSE: 0.131; Beta RMSE: 0.336\n",
      "[Epoch  1100] ELBO: 16124; Loglik: -12883; Acc.: 0.471; Alpha RMSE: 0.133; Beta RMSE: 0.304\n",
      "[Epoch  1200] ELBO: 16766; Loglik: -12942; Acc.: 0.467; Alpha RMSE: 0.127; Beta RMSE: 0.250\n",
      "[Epoch  1300] ELBO: 15809; Loglik: -12730; Acc.: 0.476; Alpha RMSE: 0.145; Beta RMSE: 0.205\n",
      "[Epoch  1400] ELBO: 16040; Loglik: -12847; Acc.: 0.472; Alpha RMSE: 0.150; Beta RMSE: 0.163\n",
      "[Epoch  1500] ELBO: 15583; Loglik: -12741; Acc.: 0.472; Alpha RMSE: 0.125; Beta RMSE: 0.119\n",
      "[Epoch  1600] ELBO: 16039; Loglik: -12643; Acc.: 0.484; Alpha RMSE: 0.122; Beta RMSE: 0.077\n",
      "[Epoch  1700] ELBO: 15537; Loglik: -12819; Acc.: 0.480; Alpha RMSE: 0.139; Beta RMSE: 0.076\n",
      "[Epoch  1800] ELBO: 15659; Loglik: -12752; Acc.: 0.475; Alpha RMSE: 0.139; Beta RMSE: 0.059\n",
      "[Epoch  1900] ELBO: 15651; Loglik: -12671; Acc.: 0.478; Alpha RMSE: 0.153; Beta RMSE: 0.039\n",
      "[Epoch  2000] ELBO: 15426; Loglik: -12701; Acc.: 0.482; Alpha RMSE: 0.142; Beta RMSE: 0.063\n",
      "[Epoch  2100] ELBO: 15387; Loglik: -12687; Acc.: 0.482; Alpha RMSE: 0.153; Beta RMSE: 0.064\n",
      "[Epoch  2200] ELBO: 15590; Loglik: -12694; Acc.: 0.480; Alpha RMSE: 0.136; Beta RMSE: 0.069\n",
      "[Epoch  2300] ELBO: 15319; Loglik: -12693; Acc.: 0.479; Alpha RMSE: 0.150; Beta RMSE: 0.083\n",
      "[Epoch  2400] ELBO: 15224; Loglik: -12673; Acc.: 0.481; Alpha RMSE: 0.156; Beta RMSE: 0.094\n",
      "[Epoch  2500] ELBO: 15341; Loglik: -12709; Acc.: 0.485; Alpha RMSE: 0.140; Beta RMSE: 0.106\n",
      "[Epoch  2600] ELBO: 15169; Loglik: -12754; Acc.: 0.475; Alpha RMSE: 0.134; Beta RMSE: 0.117\n",
      "[Epoch  2700] ELBO: 15182; Loglik: -12819; Acc.: 0.473; Alpha RMSE: 0.125; Beta RMSE: 0.116\n",
      "[Epoch  2800] ELBO: 15234; Loglik: -12787; Acc.: 0.471; Alpha RMSE: 0.138; Beta RMSE: 0.116\n",
      "[Epoch  2900] ELBO: 15190; Loglik: -12786; Acc.: 0.474; Alpha RMSE: 0.139; Beta RMSE: 0.121\n",
      "[Epoch  3000] ELBO: 15314; Loglik: -12785; Acc.: 0.466; Alpha RMSE: 0.141; Beta RMSE: 0.115\n",
      "[Epoch  3100] ELBO: 15229; Loglik: -12920; Acc.: 0.476; Alpha RMSE: 0.133; Beta RMSE: 0.118\n",
      "[Epoch  3200] ELBO: 15133; Loglik: -12856; Acc.: 0.474; Alpha RMSE: 0.131; Beta RMSE: 0.120\n",
      "[Epoch  3300] ELBO: 15063; Loglik: -12775; Acc.: 0.472; Alpha RMSE: 0.132; Beta RMSE: 0.118\n",
      "[Epoch  3400] ELBO: 15055; Loglik: -12773; Acc.: 0.474; Alpha RMSE: 0.114; Beta RMSE: 0.108\n",
      "[Epoch  3500] ELBO: 15164; Loglik: -12978; Acc.: 0.463; Alpha RMSE: 0.124; Beta RMSE: 0.125\n",
      "[Epoch  3600] ELBO: 15109; Loglik: -12950; Acc.: 0.470; Alpha RMSE: 0.123; Beta RMSE: 0.114\n",
      "[Epoch  3700] ELBO: 15039; Loglik: -12929; Acc.: 0.465; Alpha RMSE: 0.118; Beta RMSE: 0.108\n",
      "[Epoch  3800] ELBO: 15060; Loglik: -12982; Acc.: 0.465; Alpha RMSE: 0.122; Beta RMSE: 0.111\n",
      "[Epoch  3900] ELBO: 15139; Loglik: -13043; Acc.: 0.460; Alpha RMSE: 0.120; Beta RMSE: 0.097\n",
      "[Epoch  4000] ELBO: 14984; Loglik: -12943; Acc.: 0.467; Alpha RMSE: 0.100; Beta RMSE: 0.090\n",
      "[Epoch  4100] ELBO: 14974; Loglik: -12993; Acc.: 0.460; Alpha RMSE: 0.110; Beta RMSE: 0.086\n",
      "[Epoch  4200] ELBO: 15082; Loglik: -13103; Acc.: 0.457; Alpha RMSE: 0.090; Beta RMSE: 0.089\n",
      "[Epoch  4300] ELBO: 14940; Loglik: -13018; Acc.: 0.469; Alpha RMSE: 0.096; Beta RMSE: 0.068\n",
      "[Epoch  4400] ELBO: 14950; Loglik: -13054; Acc.: 0.455; Alpha RMSE: 0.105; Beta RMSE: 0.081\n",
      "[Epoch  4500] ELBO: 15025; Loglik: -13128; Acc.: 0.451; Alpha RMSE: 0.098; Beta RMSE: 0.078\n",
      "[Epoch  4600] ELBO: 14954; Loglik: -13065; Acc.: 0.456; Alpha RMSE: 0.088; Beta RMSE: 0.066\n",
      "[Epoch  4700] ELBO: 14975; Loglik: -13146; Acc.: 0.458; Alpha RMSE: 0.088; Beta RMSE: 0.073\n",
      "[Epoch  4800] ELBO: 15008; Loglik: -13191; Acc.: 0.447; Alpha RMSE: 0.090; Beta RMSE: 0.052\n",
      "[Epoch  4900] ELBO: 14986; Loglik: -13225; Acc.: 0.454; Alpha RMSE: 0.089; Beta RMSE: 0.062\n",
      "[Epoch  5000] ELBO: 14927; Loglik: -13162; Acc.: 0.449; Alpha RMSE: 0.100; Beta RMSE: 0.054\n",
      "[Epoch  5100] ELBO: 14883; Loglik: -13123; Acc.: 0.458; Alpha RMSE: 0.078; Beta RMSE: 0.046\n",
      "[Epoch  5200] ELBO: 14873; Loglik: -13180; Acc.: 0.451; Alpha RMSE: 0.084; Beta RMSE: 0.058\n",
      "[Epoch  5300] ELBO: 14917; Loglik: -13220; Acc.: 0.444; Alpha RMSE: 0.080; Beta RMSE: 0.055\n",
      "[Epoch  5400] ELBO: 14888; Loglik: -13230; Acc.: 0.449; Alpha RMSE: 0.079; Beta RMSE: 0.049\n",
      "[Epoch  5500] ELBO: 14883; Loglik: -13252; Acc.: 0.446; Alpha RMSE: 0.081; Beta RMSE: 0.059\n",
      "[Epoch  5600] ELBO: 14936; Loglik: -13295; Acc.: 0.449; Alpha RMSE: 0.086; Beta RMSE: 0.052\n",
      "[Epoch  5700] ELBO: 14864; Loglik: -13239; Acc.: 0.451; Alpha RMSE: 0.071; Beta RMSE: 0.042\n",
      "[Epoch  5800] ELBO: 14828; Loglik: -13238; Acc.: 0.448; Alpha RMSE: 0.084; Beta RMSE: 0.053\n",
      "[Epoch  5900] ELBO: 14817; Loglik: -13241; Acc.: 0.449; Alpha RMSE: 0.081; Beta RMSE: 0.051\n",
      "[Epoch  6000] ELBO: 14838; Loglik: -13302; Acc.: 0.452; Alpha RMSE: 0.070; Beta RMSE: 0.045\n",
      "[Epoch  6100] ELBO: 14905; Loglik: -13346; Acc.: 0.438; Alpha RMSE: 0.072; Beta RMSE: 0.033\n",
      "[Epoch  6200] ELBO: 14772; Loglik: -13251; Acc.: 0.453; Alpha RMSE: 0.069; Beta RMSE: 0.042\n",
      "[Epoch  6300] ELBO: 14814; Loglik: -13282; Acc.: 0.446; Alpha RMSE: 0.084; Beta RMSE: 0.046\n",
      "[Epoch  6400] ELBO: 14819; Loglik: -13302; Acc.: 0.443; Alpha RMSE: 0.066; Beta RMSE: 0.034\n",
      "[Epoch  6500] ELBO: 14910; Loglik: -13403; Acc.: 0.440; Alpha RMSE: 0.071; Beta RMSE: 0.030\n",
      "[Epoch  6600] ELBO: 14782; Loglik: -13260; Acc.: 0.446; Alpha RMSE: 0.057; Beta RMSE: 0.026\n",
      "[Epoch  6700] ELBO: 14828; Loglik: -13346; Acc.: 0.446; Alpha RMSE: 0.069; Beta RMSE: 0.034\n",
      "[Epoch  6800] ELBO: 14779; Loglik: -13328; Acc.: 0.446; Alpha RMSE: 0.087; Beta RMSE: 0.032\n",
      "[Epoch  6900] ELBO: 14847; Loglik: -13406; Acc.: 0.442; Alpha RMSE: 0.077; Beta RMSE: 0.035\n",
      "[Epoch  7000] ELBO: 14789; Loglik: -13341; Acc.: 0.442; Alpha RMSE: 0.070; Beta RMSE: 0.038\n",
      "[Epoch  7100] ELBO: 14799; Loglik: -13350; Acc.: 0.448; Alpha RMSE: 0.076; Beta RMSE: 0.030\n",
      "[Epoch  7200] ELBO: 14794; Loglik: -13374; Acc.: 0.443; Alpha RMSE: 0.066; Beta RMSE: 0.028\n",
      "[Epoch  7300] ELBO: 14847; Loglik: -13409; Acc.: 0.442; Alpha RMSE: 0.078; Beta RMSE: 0.031\n",
      "[Epoch  7400] ELBO: 14847; Loglik: -13430; Acc.: 0.437; Alpha RMSE: 0.054; Beta RMSE: 0.032\n",
      "[Epoch  7500] ELBO: 14797; Loglik: -13401; Acc.: 0.446; Alpha RMSE: 0.063; Beta RMSE: 0.027\n",
      "[Epoch  7600] ELBO: 14789; Loglik: -13384; Acc.: 0.443; Alpha RMSE: 0.056; Beta RMSE: 0.022\n",
      "[Epoch  7700] ELBO: 14821; Loglik: -13411; Acc.: 0.440; Alpha RMSE: 0.066; Beta RMSE: 0.019\n",
      "[Epoch  7800] ELBO: 14777; Loglik: -13394; Acc.: 0.441; Alpha RMSE: 0.078; Beta RMSE: 0.018\n",
      "[Epoch  7900] ELBO: 14762; Loglik: -13364; Acc.: 0.441; Alpha RMSE: 0.076; Beta RMSE: 0.022\n",
      "[Epoch  8000] ELBO: 14807; Loglik: -13438; Acc.: 0.436; Alpha RMSE: 0.076; Beta RMSE: 0.024\n",
      "[Epoch  8100] ELBO: 14810; Loglik: -13434; Acc.: 0.440; Alpha RMSE: 0.079; Beta RMSE: 0.013\n",
      "[Epoch  8200] ELBO: 14780; Loglik: -13401; Acc.: 0.442; Alpha RMSE: 0.071; Beta RMSE: 0.021\n",
      "[Epoch  8300] ELBO: 14796; Loglik: -13444; Acc.: 0.434; Alpha RMSE: 0.067; Beta RMSE: 0.031\n",
      "[Epoch  8400] ELBO: 14762; Loglik: -13425; Acc.: 0.441; Alpha RMSE: 0.075; Beta RMSE: 0.020\n",
      "[Epoch  8500] ELBO: 14777; Loglik: -13430; Acc.: 0.435; Alpha RMSE: 0.064; Beta RMSE: 0.027\n",
      "[Epoch  8600] ELBO: 14836; Loglik: -13484; Acc.: 0.432; Alpha RMSE: 0.078; Beta RMSE: 0.026\n",
      "[Epoch  8700] ELBO: 14829; Loglik: -13497; Acc.: 0.434; Alpha RMSE: 0.062; Beta RMSE: 0.022\n",
      "[Epoch  8800] ELBO: 14815; Loglik: -13479; Acc.: 0.439; Alpha RMSE: 0.076; Beta RMSE: 0.018\n",
      "[Epoch  8900] ELBO: 14846; Loglik: -13520; Acc.: 0.430; Alpha RMSE: 0.059; Beta RMSE: 0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  9000] ELBO: 14815; Loglik: -13500; Acc.: 0.434; Alpha RMSE: 0.079; Beta RMSE: 0.020\n",
      "[Epoch  9100] ELBO: 14803; Loglik: -13470; Acc.: 0.434; Alpha RMSE: 0.056; Beta RMSE: 0.016\n",
      "[Epoch  9200] ELBO: 14828; Loglik: -13517; Acc.: 0.435; Alpha RMSE: 0.066; Beta RMSE: 0.016\n",
      "[Epoch  9300] ELBO: 14795; Loglik: -13480; Acc.: 0.432; Alpha RMSE: 0.074; Beta RMSE: 0.018\n",
      "[Epoch  9400] ELBO: 14803; Loglik: -13487; Acc.: 0.432; Alpha RMSE: 0.068; Beta RMSE: 0.023\n",
      "[Epoch  9500] ELBO: 14727; Loglik: -13411; Acc.: 0.440; Alpha RMSE: 0.074; Beta RMSE: 0.017\n",
      "[Epoch  9600] ELBO: 14840; Loglik: -13529; Acc.: 0.437; Alpha RMSE: 0.053; Beta RMSE: 0.023\n",
      "[Epoch  9700] ELBO: 14782; Loglik: -13475; Acc.: 0.436; Alpha RMSE: 0.057; Beta RMSE: 0.025\n",
      "[Epoch  9800] ELBO: 14771; Loglik: -13473; Acc.: 0.437; Alpha RMSE: 0.063; Beta RMSE: 0.017\n",
      "[Epoch  9900] ELBO: 14806; Loglik: -13512; Acc.: 0.433; Alpha RMSE: 0.076; Beta RMSE: 0.019\n",
      "[Epoch 10000] ELBO: 14887; Loglik: -13599; Acc.: 0.435; Alpha RMSE: 0.070; Beta RMSE: 0.014\n",
      "[Epoch 10100] ELBO: 14740; Loglik: -13440; Acc.: 0.439; Alpha RMSE: 0.070; Beta RMSE: 0.018\n",
      "[Epoch 10200] ELBO: 14828; Loglik: -13533; Acc.: 0.433; Alpha RMSE: 0.069; Beta RMSE: 0.024\n",
      "[Epoch 10300] ELBO: 14780; Loglik: -13500; Acc.: 0.437; Alpha RMSE: 0.075; Beta RMSE: 0.018\n",
      "[Epoch 10400] ELBO: 14852; Loglik: -13575; Acc.: 0.430; Alpha RMSE: 0.071; Beta RMSE: 0.018\n",
      "[Epoch 10500] ELBO: 14907; Loglik: -13634; Acc.: 0.421; Alpha RMSE: 0.070; Beta RMSE: 0.018\n",
      "[Epoch 10600] ELBO: 14761; Loglik: -13480; Acc.: 0.437; Alpha RMSE: 0.068; Beta RMSE: 0.017\n",
      "[Epoch 10700] ELBO: 14854; Loglik: -13585; Acc.: 0.430; Alpha RMSE: 0.063; Beta RMSE: 0.011\n",
      "[Epoch 10800] ELBO: 14766; Loglik: -13486; Acc.: 0.437; Alpha RMSE: 0.054; Beta RMSE: 0.015\n",
      "[Epoch 10900] ELBO: 14769; Loglik: -13507; Acc.: 0.437; Alpha RMSE: 0.056; Beta RMSE: 0.013\n",
      "[Epoch 11000] ELBO: 14831; Loglik: -13564; Acc.: 0.428; Alpha RMSE: 0.057; Beta RMSE: 0.014\n",
      "[Epoch 11100] ELBO: 14827; Loglik: -13554; Acc.: 0.437; Alpha RMSE: 0.085; Beta RMSE: 0.015\n",
      "[Epoch 11200] ELBO: 14802; Loglik: -13513; Acc.: 0.432; Alpha RMSE: 0.066; Beta RMSE: 0.016\n",
      "[Epoch 11300] ELBO: 14814; Loglik: -13553; Acc.: 0.432; Alpha RMSE: 0.065; Beta RMSE: 0.017\n",
      "[Epoch 11400] ELBO: 14760; Loglik: -13486; Acc.: 0.429; Alpha RMSE: 0.071; Beta RMSE: 0.018\n",
      "[Epoch 11500] ELBO: 14773; Loglik: -13504; Acc.: 0.430; Alpha RMSE: 0.065; Beta RMSE: 0.017\n",
      "[Epoch 11600] ELBO: 14770; Loglik: -13495; Acc.: 0.438; Alpha RMSE: 0.055; Beta RMSE: 0.017\n",
      "[Epoch 11700] ELBO: 14788; Loglik: -13525; Acc.: 0.436; Alpha RMSE: 0.069; Beta RMSE: 0.015\n",
      "[Epoch 11800] ELBO: 14771; Loglik: -13508; Acc.: 0.435; Alpha RMSE: 0.070; Beta RMSE: 0.008\n",
      "[Epoch 11900] ELBO: 14752; Loglik: -13498; Acc.: 0.435; Alpha RMSE: 0.071; Beta RMSE: 0.015\n",
      "[Epoch 12000] ELBO: 14767; Loglik: -13509; Acc.: 0.430; Alpha RMSE: 0.065; Beta RMSE: 0.014\n",
      "[Epoch 12100] ELBO: 14762; Loglik: -13503; Acc.: 0.438; Alpha RMSE: 0.049; Beta RMSE: 0.019\n",
      "[Epoch 12200] ELBO: 14814; Loglik: -13551; Acc.: 0.436; Alpha RMSE: 0.066; Beta RMSE: 0.010\n",
      "[Epoch 12300] ELBO: 14788; Loglik: -13534; Acc.: 0.435; Alpha RMSE: 0.052; Beta RMSE: 0.014\n",
      "[Epoch 12400] ELBO: 14759; Loglik: -13505; Acc.: 0.434; Alpha RMSE: 0.055; Beta RMSE: 0.014\n",
      "[Epoch 12500] ELBO: 14841; Loglik: -13575; Acc.: 0.432; Alpha RMSE: 0.062; Beta RMSE: 0.012\n",
      "[Epoch 12600] ELBO: 14793; Loglik: -13527; Acc.: 0.436; Alpha RMSE: 0.056; Beta RMSE: 0.011\n",
      "[Epoch 12700] ELBO: 14784; Loglik: -13522; Acc.: 0.432; Alpha RMSE: 0.042; Beta RMSE: 0.017\n",
      "[Epoch 12800] ELBO: 14841; Loglik: -13596; Acc.: 0.429; Alpha RMSE: 0.066; Beta RMSE: 0.015\n",
      "[Epoch 12900] ELBO: 14724; Loglik: -13469; Acc.: 0.429; Alpha RMSE: 0.061; Beta RMSE: 0.015\n",
      "[Epoch 13000] ELBO: 14799; Loglik: -13545; Acc.: 0.429; Alpha RMSE: 0.057; Beta RMSE: 0.012\n",
      "[Epoch 13100] ELBO: 14808; Loglik: -13558; Acc.: 0.432; Alpha RMSE: 0.067; Beta RMSE: 0.015\n",
      "[Epoch 13200] ELBO: 14757; Loglik: -13505; Acc.: 0.445; Alpha RMSE: 0.063; Beta RMSE: 0.015\n",
      "[Epoch 13300] ELBO: 14847; Loglik: -13593; Acc.: 0.424; Alpha RMSE: 0.066; Beta RMSE: 0.010\n",
      "[Epoch 13400] ELBO: 14806; Loglik: -13570; Acc.: 0.429; Alpha RMSE: 0.062; Beta RMSE: 0.013\n",
      "[Epoch 13500] ELBO: 14877; Loglik: -13635; Acc.: 0.426; Alpha RMSE: 0.059; Beta RMSE: 0.018\n",
      "[Epoch 13600] ELBO: 14789; Loglik: -13543; Acc.: 0.435; Alpha RMSE: 0.065; Beta RMSE: 0.013\n",
      "[Epoch 13700] ELBO: 14807; Loglik: -13553; Acc.: 0.434; Alpha RMSE: 0.069; Beta RMSE: 0.013\n",
      "[Epoch 13800] ELBO: 14803; Loglik: -13558; Acc.: 0.430; Alpha RMSE: 0.073; Beta RMSE: 0.014\n",
      "[Epoch 13900] ELBO: 14759; Loglik: -13514; Acc.: 0.434; Alpha RMSE: 0.073; Beta RMSE: 0.017\n",
      "[Epoch 14000] ELBO: 14865; Loglik: -13623; Acc.: 0.426; Alpha RMSE: 0.059; Beta RMSE: 0.020\n",
      "[Epoch 14100] ELBO: 14806; Loglik: -13562; Acc.: 0.433; Alpha RMSE: 0.075; Beta RMSE: 0.013\n",
      "[Epoch 14200] ELBO: 14818; Loglik: -13568; Acc.: 0.436; Alpha RMSE: 0.075; Beta RMSE: 0.011\n",
      "[Epoch 14300] ELBO: 14743; Loglik: -13507; Acc.: 0.436; Alpha RMSE: 0.052; Beta RMSE: 0.011\n",
      "[Epoch 14400] ELBO: 14793; Loglik: -13564; Acc.: 0.435; Alpha RMSE: 0.061; Beta RMSE: 0.017\n",
      "[Epoch 14500] ELBO: 14897; Loglik: -13654; Acc.: 0.425; Alpha RMSE: 0.052; Beta RMSE: 0.008\n",
      "[Epoch 14600] ELBO: 14776; Loglik: -13546; Acc.: 0.436; Alpha RMSE: 0.075; Beta RMSE: 0.011\n",
      "[Epoch 14700] ELBO: 14883; Loglik: -13642; Acc.: 0.428; Alpha RMSE: 0.055; Beta RMSE: 0.018\n",
      "[Epoch 14800] ELBO: 14770; Loglik: -13543; Acc.: 0.426; Alpha RMSE: 0.061; Beta RMSE: 0.015\n",
      "[Epoch 14900] ELBO: 14791; Loglik: -13551; Acc.: 0.433; Alpha RMSE: 0.062; Beta RMSE: 0.012\n",
      "[Epoch 15000] ELBO: 14835; Loglik: -13596; Acc.: 0.433; Alpha RMSE: 0.062; Beta RMSE: 0.011\n",
      "[Epoch 15100] ELBO: 14779; Loglik: -13538; Acc.: 0.436; Alpha RMSE: 0.058; Beta RMSE: 0.014\n",
      "[Epoch 15200] ELBO: 14803; Loglik: -13563; Acc.: 0.433; Alpha RMSE: 0.063; Beta RMSE: 0.014\n",
      "[Epoch 15300] ELBO: 14798; Loglik: -13554; Acc.: 0.421; Alpha RMSE: 0.061; Beta RMSE: 0.016\n",
      "[Epoch 15400] ELBO: 14776; Loglik: -13531; Acc.: 0.432; Alpha RMSE: 0.072; Beta RMSE: 0.013\n",
      "[Epoch 15500] ELBO: 14805; Loglik: -13571; Acc.: 0.430; Alpha RMSE: 0.044; Beta RMSE: 0.012\n",
      "[Epoch 15600] ELBO: 14765; Loglik: -13521; Acc.: 0.433; Alpha RMSE: 0.067; Beta RMSE: 0.011\n",
      "[Epoch 15700] ELBO: 14828; Loglik: -13577; Acc.: 0.433; Alpha RMSE: 0.063; Beta RMSE: 0.017\n",
      "[Epoch 15800] ELBO: 14769; Loglik: -13529; Acc.: 0.430; Alpha RMSE: 0.039; Beta RMSE: 0.011\n",
      "[Epoch 15900] ELBO: 14776; Loglik: -13547; Acc.: 0.432; Alpha RMSE: 0.074; Beta RMSE: 0.019\n",
      "[Epoch 16000] ELBO: 14813; Loglik: -13595; Acc.: 0.430; Alpha RMSE: 0.058; Beta RMSE: 0.017\n",
      "[Epoch 16100] ELBO: 14753; Loglik: -13520; Acc.: 0.432; Alpha RMSE: 0.065; Beta RMSE: 0.016\n",
      "[Epoch 16200] ELBO: 14779; Loglik: -13560; Acc.: 0.427; Alpha RMSE: 0.063; Beta RMSE: 0.013\n",
      "[Epoch 16300] ELBO: 14767; Loglik: -13534; Acc.: 0.433; Alpha RMSE: 0.067; Beta RMSE: 0.019\n",
      "[Epoch 16400] ELBO: 14770; Loglik: -13538; Acc.: 0.433; Alpha RMSE: 0.059; Beta RMSE: 0.012\n",
      "[Epoch 16500] ELBO: 14760; Loglik: -13520; Acc.: 0.434; Alpha RMSE: 0.076; Beta RMSE: 0.013\n",
      "[Epoch 16600] ELBO: 14756; Loglik: -13514; Acc.: 0.434; Alpha RMSE: 0.052; Beta RMSE: 0.012\n",
      "[Epoch 16700] ELBO: 14842; Loglik: -13592; Acc.: 0.428; Alpha RMSE: 0.055; Beta RMSE: 0.016\n",
      "[Epoch 16800] ELBO: 14740; Loglik: -13515; Acc.: 0.441; Alpha RMSE: 0.050; Beta RMSE: 0.013\n",
      "[Epoch 16900] ELBO: 14755; Loglik: -13509; Acc.: 0.435; Alpha RMSE: 0.059; Beta RMSE: 0.016\n",
      "[Epoch 17000] ELBO: 14761; Loglik: -13520; Acc.: 0.433; Alpha RMSE: 0.047; Beta RMSE: 0.011\n",
      "[Epoch 17100] ELBO: 14790; Loglik: -13565; Acc.: 0.428; Alpha RMSE: 0.054; Beta RMSE: 0.017\n",
      "[Epoch 17200] ELBO: 14743; Loglik: -13506; Acc.: 0.431; Alpha RMSE: 0.049; Beta RMSE: 0.012\n",
      "[Epoch 17300] ELBO: 14748; Loglik: -13518; Acc.: 0.436; Alpha RMSE: 0.066; Beta RMSE: 0.016\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/code/amortized-mxl-dev/release/core/torch_mxl_ard.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, num_epochs, true_alpha, true_beta, true_beta_resp)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 \u001b[0melbo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_alt_av_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_mask_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_alt_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0melbo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/amortized-mxl-dev/release/core/torch_mxl_ard.py\u001b[0m in \u001b[0;36melbo\u001b[0;34m(self, alt_attr, context_attr, obs_choices, alt_avail, obs_mask, alt_ids, indices)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# compute accuracy based on utilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobs_choices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mobs_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from core.torch_mxl_ard import TorchMXL_ARD\n",
    "\n",
    "# instantiate MXL model\n",
    "mxl = TorchMXL_ARD(dcm_dataset, batch_size=num_resp, use_inference_net=False, use_cuda=True)\n",
    "\n",
    "# run Bayesian inference (variational inference)\n",
    "results = mxl.infer(num_epochs=20000, true_alpha=true_alpha, true_beta=true_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9329,  0.7962, 25.1169], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxl.softplus(mxl.tau_alpha_alpha) / mxl.softplus(mxl.tau_alpha_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0719, 1.2560, 0.0398], device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(mxl.softplus(mxl.tau_alpha_alpha) / mxl.softplus(mxl.tau_alpha_beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0584, 1.0380, 1.3097, 1.0221, 0.0225], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(mxl.softplus(mxl.tau_zeta_alpha) / mxl.softplus(mxl.tau_zeta_beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"results\" dictionary containts a summary of the results of variational inference, including means of the posterior approximations for the different parameters in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Estimation time': 209.87697911262512,\n",
       " 'Est. alpha': array([-0.84820074,  0.8947073 , -0.0018831 ], dtype=float32),\n",
       " 'Est. zeta': array([-0.8228174 ,  0.81418836,  0.9868169 , -0.8160901 ,  0.00254723],\n",
       "       dtype=float32),\n",
       " 'Est. beta_n': array([[-1.2766652 ,  0.3046328 ,  0.51390994, -1.0039337 , -0.49254796],\n",
       "        [-0.5603233 ,  1.3532368 ,  1.396333  , -0.37009713,  0.5938316 ],\n",
       "        [-1.7567154 , -0.53884834,  0.02093476, -1.8624086 , -0.96905404],\n",
       "        ...,\n",
       "        [ 0.23850892,  2.0993855 ,  2.337171  ,  0.45950678,  1.5387936 ],\n",
       "        [-0.8100392 ,  0.85312676,  1.0481509 , -0.7168947 , -0.045082  ],\n",
       "        [-0.67406833,  1.2005583 ,  1.1898443 , -0.5693627 ,  0.09904347]],\n",
       "       dtype=float32),\n",
       " 'ELBO': 14791.0166015625,\n",
       " 'Loglikelihood': -13572.5126953125,\n",
       " 'Accuracy': 0.428600013256073}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interface is currently being improved to include additional output information, but additional information can be obtained from the attributes of the \"mxl\" object for now. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
